---
title: "楊子萱_110700049_hw06"
author: "楊子萱"
date: "2023-10-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

In order to perform the different types of regression models, I decided to use the dataset about **Sleep health and lifestyle**. The regression techniques I will be using are listed below. To prevent the problem of **over-fitting**, I will split the data into **training** set, **validation** set, and **test** set. I will not only **explain** the results I obtain, but also **compare** the results between different models. Last but not least, I will be discussing some possible problems for future studies.

# Regression Techniques

**1. Parametric Regression Models**

    a. Simple Linear Regression
  
    b. Polynomial Linear Regression

**2. Nonparametric Regression Models**

    a. Kernal Regression
  
    b. Regression Trees
    
    c. Locally Weighted Regression
  
## Check Type & Structure of Data 
```{r}
data = read.csv(file = 'Sleep_health_and_lifestyle_dataset.csv', header = TRUE, sep = ',')
class(data)
str(data)
cat("Number of rows with missing values:", sum(!complete.cases(data)), "\n")

missing_counts <- colSums(is.na(data))
columns_with_missing <- sum(missing_counts > 0)
cat("Number of columns with missing values:", columns_with_missing, "\n")

if (columns_with_missing > 0) {
  cat("Columns with missing values:", paste(names(missing_counts[missing_counts > 0]), collapse = ", "), "\n")
}
```
  
# Split into Sets

I will split the data into **70%** training, **15%** validation, and **15%** test sets.

```{r}
library(caret)

trainIndex <- createDataPartition(data$Quality.of.Sleep, p = 0.7, 
                                  list = FALSE)
train <- data[trainIndex, ]
data <- data[-trainIndex, ]

validIndex <- createDataPartition(data$Quality.of.Sleep, p = 0.5, 
                                  list = FALSE)
valid <- data[validIndex, ]
test <- data[-validIndex, ]

n_train <- nrow(train)
n_valid <- nrow(valid)
n_test <- nrow(test)

cat("Number of data points in the training set:", n_train, "\n")
cat("Number of data points in the validation set:", n_valid, "\n")
cat("Number of data points in the test set:", n_test, "\n")
```

## Summary of Correlation
```{r}
library(corrplot)

num_col <- sapply(train, function(x) is.numeric(x))
num <- train[, num_col]

correlation_matrix <- cor(num, use = "complete.obs")

corrplot(correlation_matrix,
         method = "color",  
         type = "upper", 
         tl.cex = 0.7,   
         tl.col = "black" 
)
```

```{r}
library(psych)

pairs.panels(num, 
             method = "pearson", 
             hist.col = "lightblue",
             density = TRUE,
             ellipses = TRUE, 
             main = "Correlation Plot with Histograms and Scatter Plots",
             gap = 0
)
```
  
# 1. Parametric Regression Models
## a. Simple Linear Regression
### Quality.of.Sleep v.s. Age
```{r}
model <- lm(Age ~ Quality.of.Sleep, data = train)
model_summary <- summary(model)
print(model_summary)

coefficients <- model_summary$coefficients
intercept <- coefficients["(Intercept)", "Estimate"]
slope <- coefficients["Quality.of.Sleep", "Estimate"]

cat("Simple Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(slope, 2), "x\n")

residuals <- residuals(model)
SSE <- sum(residuals^2)
TSS <- sum((train$Age - mean(train$Age))^2)
n <- nrow(train)
RSE <- sqrt(SSE / (n - 2))

cat("Residual Standard Error (RSE):", RSE, "\n")
cat("Total Sum of Squares (TSS):", TSS, "\n")

coefficient_estimate <- coef(model)["Quality.of.Sleep"]
standard_error <- summary(model)$coef["Quality.of.Sleep", "Std. Error"]

t_statistic <- coefficient_estimate / standard_error

df <- nrow(train) - 2

alpha <- 0.05

p_value <- 2 * (1 - pt(abs(t_statistic), df))

if (p_value < alpha) {
  cat("Reject the null hypothesis. The coefficient is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The coefficient is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Age, main = "Simple Linear Regression (Training Set)", xlab = "X", ylab = "Y")
abline(model, col = "red")
```

#### Test against Validation Set
```{r}
predictors <- attr(model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_age <- predict(model, newdata = valid)
mse <- mean((valid$Age - predicted_age)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Age - predicted_age)^2) / sum((valid$Age - mean(valid$Age))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_model <- sum(model$residuals^2)
n_model <- length(model$residuals)
p_model <- number_of_predictors
Cp_model <- (SSE_model / mse) - (n_model - 2 * p_model)
AIC_model <- n_model * log(SSE_model / n_model) + 2 * (p_model + 1)
BIC_model <- n_model * log(SSE_model / n_model) + (p_model + 1) * log(n_model)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Model:", p_model, "\n")
cat("Mallow's Cp for the Model:", Cp_model, "\n")
cat("AIC for the Model:", AIC_model, "\n")
cat("BIC for the Model:", BIC_model, "\n")

plot(valid$Quality.of.Sleep, valid$Age, main = "Simple Linear Regression (Validation Set)", xlab = "X", ylab = "Y")
abline(model, col = "blue")
points(valid$Quality.of.Sleep, predicted_age, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
predicted_age_test <- predict(model, newdata = test)
mse_test <- mean((test$Age - predicted_age_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- length(predictors)

r_squared_test <- 1 - (sum((test$Age - predicted_age_test)^2) / sum((test$Age - mean(test$Age))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)

SSE_model_test <- sum((test$Age - predicted_age_test)^2)
n_model_test <- n_test
p_model_test <- k_test
Cp_model_test <- (SSE_model_test / mse_test) - (n_model_test - 2 * p_model_test)
AIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + 2 * (p_model_test + 1)
BIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + (p_model_test + 1) * log(n_model_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Model on the test set:", p_model_test, "\n")
cat("Mallow's Cp for the Model on the test set:", Cp_model_test, "\n")
cat("AIC for the Model on the test set:", AIC_model_test, "\n")
cat("BIC for the Model on the test set:", BIC_model_test, "\n")

plot(test$Quality.of.Sleep, test$Age, main = "Simple Linear Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Age")
abline(model, col = "blue")
points(test$Quality.of.Sleep, predicted_age_test, col = "red", pch = 20)
```

From the above plots, we can see that the quality of sleep and age have a **positive correlation**. The values of **RSE**, **RMSE**, and **adjusted R-squared** for the training, validation, and test sets suggest that the model's performance is somewhat **consistent** across these different datasets. The model has **relatively high RSE values**, suggesting that the model's predictions have a considerable amount of error. The **adjusted R-squared values** for both validation and test sets are relatively **low**, indicating that the model's ability to explain the variance in Age is limited.

Improvements to consider:

The model may benefit from additional predictor variables or a more complex model to better explain the variance in Age.


### Quality.of.Sleep v.s. Sleep.Duration
```{r}
model <- lm(Sleep.Duration ~ Quality.of.Sleep, data = train)
model_summary <- summary(model)
print(model_summary)

coefficients <- model_summary$coefficients

intercept <- coefficients["(Intercept)", "Estimate"]
slope <- coefficients["Quality.of.Sleep", "Estimate"]

cat("Simple Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(slope, 2), "x\n")

residuals <- residuals(model)

SSE <- sum(residuals^2)

TSS <- sum((train$Sleep.Duration - mean(train$Sleep.Duration))^2)

n <- nrow(train)
RSE <- sqrt(SSE / (n - 2))

cat("Residual Standard Error (RSE):", RSE, "\n")
cat("Total Sum of Squares (TSS):", TSS, "\n")

coefficient_estimate <- coef(model)["Quality.of.Sleep"]
standard_error <- summary(model)$coef["Quality.of.Sleep", "Std. Error"]

t_statistic <- coefficient_estimate / standard_error

df <- nrow(train) - 2

alpha <- 0.05

p_value <- 2 * (1 - pt(abs(t_statistic), df))

if (p_value < alpha) {
  cat("Reject the null hypothesis. The coefficient is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The coefficient is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Sleep.Duration, main = "Simple Linear Regression (Training Set)", xlab = "X", ylab = "Y")

abline(model, col = "red")
```

#### Test against Validation Set
```{r}
predictors <- attr(model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_age <- predict(model, newdata = valid)
mse <- mean((valid$Sleep.Duration - predicted_age)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Sleep.Duration - predicted_age)^2) / sum((valid$Sleep.Duration - mean(valid$Sleep.Duration))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_model <- sum(model$residuals^2)
n_model <- length(model$residuals)
p_model <- number_of_predictors
Cp_model <- (SSE_model / mse) - (n_model - 2 * p_model)
AIC_model <- n_model * log(SSE_model / n_model) + 2 * (p_model + 1)
BIC_model <- n_model * log(SSE_model / n_model) + (p_model + 1) * log(n_model)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Model:", p_model, "\n")
cat("Mallow's Cp for the Model:", Cp_model, "\n")
cat("AIC for the Model:", AIC_model, "\n")
cat("BIC for the Model:", BIC_model, "\n")

plot(valid$Quality.of.Sleep, valid$Sleep.Duration, main = "Simple Linear Regression (Validation Set)", xlab = "X", ylab = "Y")
abline(model, col = "blue")
points(valid$Quality.of.Sleep, predicted_age, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
predicted_test <- predict(model, newdata = test)
mse_test <- mean((test$Sleep.Duration - predicted_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- length(predictors)

r_squared_test <- 1 - (sum((test$Sleep.Duration - predicted_test)^2) / sum((test$Sleep.Duration - mean(test$Sleep.Duration))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)

SSE_model_test <- sum((test$Sleep.Duration - predicted_test)^2)
n_model_test <- n_test
p_model_test <- k_test
Cp_model_test <- (SSE_model_test / mse_test) - (n_model_test - 2 * p_model_test)
AIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + 2 * (p_model_test + 1)
BIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + (p_model_test + 1) * log(n_model_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Model on the test set:", p_model_test, "\n")
cat("Mallow's Cp for the Model on the test set:", Cp_model_test, "\n")
cat("AIC for the Model on the test set:", AIC_model_test, "\n")
cat("BIC for the Model on the test set:", BIC_model_test, "\n")

plot(test$Quality.of.Sleep, test$Sleep.Duration, main = "Simple Linear Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Sleep.Duration")
abline(model, col = "blue")
points(test$Quality.of.Sleep, predicted_test, col = "red", pch = 20)
```

Overall, the model appears to **perform well**, as indicated by **low MSE and RMSE values** and **high adjusted R-squared values**. It also passes the statistical significance test for the coefficient in both training and validation sets. The test set evaluation metrics are **consistent** with the validation set, indicating that the model's performance is **stable** and **generalizes well to unseen data**. The coefficient and the line indicates that there is a **positive correlation** between sleep quality and sleep duration.


### Quality.of.Sleep v.s. Daily.Steps
```{r}
model <- lm(Daily.Steps ~ Quality.of.Sleep, data = train)
model_summary <- summary(model)
print(model_summary)

coefficients <- model_summary$coefficients

intercept <- coefficients["(Intercept)", "Estimate"]
slope <- coefficients["Quality.of.Sleep", "Estimate"]

cat("Simple Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(slope, 2), "x\n")

residuals <- residuals(model)

SSE <- sum(residuals^2)

TSS <- sum((train$Daily.Steps - mean(train$Daily.Steps))^2)

n <- nrow(train)
RSE <- sqrt(SSE / (n - 2))

cat("Residual Standard Error (RSE):", RSE, "\n")
cat("Total Sum of Squares (TSS):", TSS, "\n")

coefficient_estimate <- coef(model)["Quality.of.Sleep"]
standard_error <- summary(model)$coef["Quality.of.Sleep", "Std. Error"]

t_statistic <- coefficient_estimate / standard_error

df <- nrow(train) - 2

alpha <- 0.05

p_value <- 2 * (1 - pt(abs(t_statistic), df))

if (p_value < alpha) {
  cat("Reject the null hypothesis. The coefficient is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The coefficient is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Daily.Steps, main = "Simple Linear Regression (Training Set)", xlab = "X", ylab = "Y")
abline(model, col = "red")
```

#### Test against Validation Set
```{r}
predictors <- attr(model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_age <- predict(model, newdata = valid)
mse <- mean((valid$Daily.Steps - predicted_age)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Daily.Steps - predicted_age)^2) / sum((valid$Daily.Steps - mean(valid$Daily.Steps))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_model <- sum(model$residuals^2)
n_model <- length(model$residuals)
p_model <- number_of_predictors
Cp_model <- (SSE_model / mse) - (n_model - 2 * p_model)
AIC_model <- n_model * log(SSE_model / n_model) + 2 * (p_model + 1)
BIC_model <- n_model * log(SSE_model / n_model) + (p_model + 1) * log(n_model)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Model:", p_model, "\n")
cat("Mallow's Cp for the Model:", Cp_model, "\n")
cat("AIC for the Model:", AIC_model, "\n")
cat("BIC for the Model:", BIC_model, "\n")

plot(valid$Quality.of.Sleep, valid$Daily.Steps, main = "Simple Linear Regression (Validation Set)", xlab = "X", ylab = "Y")
abline(model, col = "blue")
points(valid$Quality.of.Sleep, predicted_age, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
predicted_test <- predict(model, newdata = test)
mse_test <- mean((test$Daily.Steps - predicted_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- length(predictors)

r_squared_test <- 1 - (sum((test$Daily.Steps - predicted_test)^2) / sum((test$Daily.Steps - mean(test$Daily.Steps))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)

SSE_model_test <- sum((test$Daily.Steps - predicted_test)^2)
n_model_test <- n_test
p_model_test <- k_test
Cp_model_test <- (SSE_model_test / mse_test) - (n_model_test - 2 * p_model_test)
AIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + 2 * (p_model_test + 1)
BIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + (p_model_test + 1) * log(n_model_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Model on the test set:", p_model_test, "\n")
cat("Mallow's Cp for the Model on the test set:", Cp_model_test, "\n")
cat("AIC for the Model on the test set:", AIC_model_test, "\n")
cat("BIC for the Model on the test set:", BIC_model_test, "\n")

plot(test$Quality.of.Sleep, test$Daily.Steps, main = "Simple Linear Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Daily.Steps")
abline(model, col = "blue")
points(test$Quality.of.Sleep, predicted_test, col = "red", pch = 20)
```

The evaluation metrics for both the validation and test sets suggest that the model of sleep quality and daily steps **does not fit** the data well and has **high prediction errors**. The **negative adjusted R-squared values** indicate that the predictors are not explaining the variance in the response variable. The **high RMSE values** and **AIC & BIC** values on the validation set and test set further support that the model's performance is **not adequate**. The plot indicates a **positive correlation**, yet the coefficients  are **not statistically significant**, and the model has a **high level of prediction error**.


### Quality.of.Sleep v.s. Physical.Activity.Level
```{r}
model <- lm(Physical.Activity.Level ~ Quality.of.Sleep, data = train)
model_summary <- summary(model)
print(model_summary)

coefficients <- model_summary$coefficients

intercept <- coefficients["(Intercept)", "Estimate"]
slope <- coefficients["Quality.of.Sleep", "Estimate"]

cat("Simple Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(slope, 2), "x\n")

residuals <- residuals(model)

SSE <- sum(residuals^2)

TSS <- sum((train$Physical.Activity.Level - mean(train$Physical.Activity.Level))^2)

n <- nrow(train)
RSE <- sqrt(SSE / (n - 2))

cat("Residual Standard Error (RSE):", RSE, "\n")
cat("Total Sum of Squares (TSS):", TSS, "\n")

coefficient_estimate <- coef(model)["Quality.of.Sleep"]
standard_error <- summary(model)$coef["Quality.of.Sleep", "Std. Error"]

t_statistic <- coefficient_estimate / standard_error

df <- nrow(train) - 2

alpha <- 0.05

p_value <- 2 * (1 - pt(abs(t_statistic), df))

if (p_value < alpha) {
  cat("Reject the null hypothesis. The coefficient is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The coefficient is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Physical.Activity.Level, main = "Simple Linear Regression (Training Set)", xlab = "X", ylab = "Y")

abline(model, col = "red")
```

#### Test against Validation Set
```{r}
predictors <- attr(model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_age <- predict(model, newdata = valid)
mse <- mean((valid$Physical.Activity.Level - predicted_age)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Physical.Activity.Level - predicted_age)^2) / sum((valid$Physical.Activity.Level - mean(valid$Physical.Activity.Level))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_model <- sum(model$residuals^2)
n_model <- length(model$residuals)
p_model <- number_of_predictors
Cp_model <- (SSE_model / mse) - (n_model - 2 * p_model)
AIC_model <- n_model * log(SSE_model / n_model) + 2 * (p_model + 1)
BIC_model <- n_model * log(SSE_model / n_model) + (p_model + 1) * log(n_model)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Model:", p_model, "\n")
cat("Mallow's Cp for the Model:", Cp_model, "\n")
cat("AIC for the Model:", AIC_model, "\n")
cat("BIC for the Model:", BIC_model, "\n")

plot(valid$Quality.of.Sleep, valid$Physical.Activity.Level, main = "Simple Linear Regression (Validation Set)", xlab = "X", ylab = "Y")
abline(model, col = "blue")
points(valid$Quality.of.Sleep, predicted_age, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
predicted_test <- predict(model, newdata = test)
mse_test <- mean((test$Physical.Activity.Level - predicted_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- length(predictors)

r_squared_test <- 1 - (sum((test$Physical.Activity.Level - predicted_test)^2) / sum((test$Physical.Activity.Level - mean(test$Physical.Activity.Level))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)

SSE_model_test <- sum((test$Physical.Activity.Level - predicted_test)^2)
n_model_test <- n_test
p_model_test <- k_test
Cp_model_test <- (SSE_model_test / mse_test) - (n_model_test - 2 * p_model_test)
AIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + 2 * (p_model_test + 1)
BIC_model_test <- n_model_test * log(SSE_model_test / n_model_test) + (p_model_test + 1) * log(n_model_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Model on the test set:", p_model_test, "\n")
cat("Mallow's Cp for the Model on the test set:", Cp_model_test, "\n")
cat("AIC for the Model on the test set:", AIC_model_test, "\n")
cat("BIC for the Model on the test set:", BIC_model_test, "\n")

plot(test$Quality.of.Sleep, test$Physical.Activity.Level, main = "Simple Linear Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Physical.Activity.Level")
abline(model, col = "blue")
points(test$Quality.of.Sleep, predicted_test, col = "red", pch = 20)
```

This simple linear regression model has a **low adjusted R-squared** on both the training and validation sets, suggesting that it explains only a **small portion** of the variance in the physical activity level variable. While the coefficient is statistically significant and indicates a **positive correlation**, the model still has **relatively high prediction errors**, as indicated by the *RSE*, **MSE**, and **RMSE** values. Additionally, **Mallow's Cp**, **AIC**, and **BIC** values suggest that the model may be **too complex**. The **adjusted R-squared** on the test set is **negative**, indicating that the model's performance is **poor on unseen data**. Overall, this model does not provide a good fit to the data.


## b. Polynomial Linear Regression
### Quality.of.Sleep v.s. Age
```{r}
poly_model <- lm(train$Age ~ poly(train$Quality.of.Sleep, 2), data = train)
model_summary <- summary(poly_model)
print(model_summary)

coefficients <- coef(poly_model)
coef_quadratic <- coefficients["poly(train$Quality.of.Sleep, 2)1"]
coef_linear <- coefficients["poly(train$Quality.of.Sleep, 2)2"]
intercept <- coefficients["(Intercept)"]

cat("Polynomial Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(coef_linear, 2), "x + ", round(coef_quadratic, 2), "x^2\n")

RSS <- sum(poly_model$residuals^2)
TSS <- sum((train$Age - mean(train$Age))^2)
p <- length(coef(poly_model))
n <- nrow(train)
F_statistic <- ((TSS - RSS) / (p - 1)) / (RSS / (n - p))
df1 <- p - 1
df2 <- n - p
alpha <- 0.05
p_value <- 1 - pf(F_statistic, df1, df2)

if (p_value < alpha) {
  cat("Reject the null hypothesis. The polynomial regression model is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The polynomial regression model is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Age, main = "Polynomial Regression (Training Set)", xlab = "X", ylab = "Y")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(poly_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```


#### Test against Validation Set
```{r}
poly_model <- lm(valid$Age ~ poly(valid$Quality.of.Sleep, 2), data = valid)
predictors <- attr(poly_model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted <- predict(poly_model, newdata = valid)
mse <- mean((valid$Age - predicted)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Age - predicted)^2) / sum((valid$Age - mean(valid$Age))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_poly <- sum(poly_model$residuals^2)
n_poly <- length(poly_model$residuals)
p_poly <- number_of_predictors
Cp_poly <- (SSE_poly / mse) - (n_poly - 2 * p_poly)
AIC_poly <- n_poly * log(SSE_poly / n_poly) + 2 * (p_poly + 1)
BIC_poly <- n_poly * log(SSE_poly / n_poly) + (p_poly + 1) * log(n_poly)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Polynomial Model:", p_poly, "\n")
cat("Mallow's Cp for the Polynomial Model:", Cp_poly, "\n")
cat("AIC for the Polynomial Model:", AIC_poly, "\n")
cat("BIC for the Polynomial Model:", BIC_poly, "\n")

plot(valid$Quality.of.Sleep, valid$Age, main = "Polynomial Regression (Validation Set)", xlab = "X", ylab = "Y")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
poly_model_test <- lm(test$Age ~ poly(test$Quality.of.Sleep, 2), data = test)
predictors <- attr(poly_model_test$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_test <- predict(poly_model_test, newdata = test)
mse_test <- mean((test$Age - predicted_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- number_of_predictors
r_squared_test <- 1 - (sum((test$Age - predicted_test)^2) / sum((test$Age - mean(test$Age))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)
SSE_poly_test <- sum(poly_model_test$residuals^2)
n_poly_test <- length(poly_model_test$residuals)
Cp_poly_test <- (SSE_poly_test / mse_test) - (n_poly_test - 2 * k_test)
AIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + 2 * (k_test + 1)
BIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + (k_test + 1) * log(n_poly_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Polynomial Model on the test set:", k_test, "\n")
cat("Mallow's Cp for the Polynomial Model on the test set:", Cp_poly_test, "\n")
cat("AIC for the Polynomial Model on the test set:", AIC_poly_test, "\n")
cat("BIC for the Polynomial Model on the test set:", BIC_poly_test, "\n")

plot(test$Quality.of.Sleep, test$Age, main = "Polynomial Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Age")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_test, col = "red", pch = 20)
```

Due to the structure of the data, the line of the polynomial regression model is like a **zig-zag shape**, instead of a smooth curve. This indicates that perhaps this is not the perfect regression model for this data. However, the evaluation metrics for the model suggest that the it has a **moderate fit** and performs well on both the validation and test sets. The **adjusted R-squared values**, although not high, indicate that the model explains a significant portion of the variance in the response variable. The **MSE** and **RMSE** values on the validation and test sets are also relatively moderate, suggesting acceptable model performance.

### Quality.of.Sleep v.s. Sleep.Duration
```{r}
poly_model <- lm(train$Sleep.Duration ~ poly(train$Quality.of.Sleep, 2), data = train)
model_summary <- summary(poly_model)
print(model_summary)

coefficients <- coef(poly_model)
coef_quadratic <- coefficients["poly(train$Quality.of.Sleep, 2)1"]
coef_linear <- coefficients["poly(train$Quality.of.Sleep, 2)2"]
intercept <- coefficients["(Intercept)"]

cat("Polynomial Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(coef_linear, 2), "x + ", round(coef_quadratic, 2), "x^2\n")

RSS <- sum(poly_model$residuals^2)
TSS <- sum((train$Sleep.Duration - mean(train$Sleep.Duration))^2)
p <- length(coef(poly_model))
n <- nrow(train)
F_statistic <- ((TSS - RSS) / (p - 1)) / (RSS / (n - p))
df1 <- p - 1
df2 <- n - p
alpha <- 0.05
p_value <- 1 - pf(F_statistic, df1, df2)

if (p_value < alpha) {
  cat("Reject the null hypothesis. The polynomial regression model is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The polynomial regression model is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Sleep.Duration, main = "Polynomial Regression", xlab = "Quality.of.Sleep", ylab = "Sleep.Duration")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(poly_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```

#### Test against Validation Set
```{r}
poly_model <- lm(valid$Sleep.Duration ~ poly(valid$Quality.of.Sleep, 2), data = valid)
predictors <- attr(poly_model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted <- predict(poly_model, newdata = valid)
mse <- mean((valid$Sleep.Duration - predicted)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Sleep.Duration - predicted)^2) / sum((valid$Sleep.Duration - mean(valid$Sleep.Duration))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_poly <- sum(poly_model$residuals^2)
n_poly <- length(poly_model$residuals)
p_poly <- number_of_predictors
Cp_poly <- (SSE_poly / mse) - (n_poly - 2 * p_poly)
AIC_poly <- n_poly * log(SSE_poly / n_poly) + 2 * (p_poly + 1)
BIC_poly <- n_poly * log(SSE_poly / n_poly) + (p_poly + 1) * log(n_poly)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Polynomial Model:", p_poly, "\n")
cat("Mallow's Cp for the Polynomial Model:", Cp_poly, "\n")
cat("AIC for the Polynomial Model:", AIC_poly, "\n")
cat("BIC for the Polynomial Model:", BIC_poly, "\n")

plot(valid$Quality.of.Sleep, valid$Sleep.Duration, main = "Polynomial Regression (Validation Set)", xlab = "Quality.of.Sleep", ylab = "Sleep.Duration")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
poly_model_test <- lm(test$Sleep.Duration ~ poly(test$Quality.of.Sleep, 2), data = test)
predictors <- attr(poly_model_test$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_test <- predict(poly_model_test, newdata = test)
mse_test <- mean((test$Sleep.Duration - predicted_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- number_of_predictors
r_squared_test <- 1 - (sum((test$Sleep.Duration - predicted_test)^2) / sum((test$Sleep.Duration - mean(test$Sleep.Duration))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)
SSE_poly_test <- sum(poly_model_test$residuals^2)
n_poly_test <- length(poly_model_test$residuals)
Cp_poly_test <- (SSE_poly_test / mse_test) - (n_poly_test - 2 * k_test)
AIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + 2 * (k_test + 1)
BIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + (k_test + 1) * log(n_poly_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Polynomial Model on the test set:", k_test, "\n")
cat("Mallow's Cp for the Polynomial Model on the test set:", Cp_poly_test, "\n")
cat("AIC for the Polynomial Model on the test set:", AIC_poly_test, "\n")
cat("BIC for the Polynomial Model on the test set:", BIC_poly_test, "\n")

plot(test$Quality.of.Sleep, test$Sleep.Duration, main = "Polynomial Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Sleep.Duration")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_test, col = "red", pch = 20)
```

Same as the previous model, due to the structure of the data, the line of the polynomial regression model is like a **zig-zag shape**, instead of a smooth curve. This indicates that perhaps this is **not the perfect** regression model for this data. Nevertheless, the evaluation metrics for this model suggest that the it's a **good fit** for the data. The **adjusted R-squared values are high**, indicating that the model explains a significant portion of the variance in the response variable. The *MSE* and *RMSE* values on the validation and test sets are **low**, indicating great prediction accuracy and a good fit for these datasets.


### Quality.of.Sleep v.s. Daily.Steps
```{r}
poly_model <- lm(train$Daily.Steps ~ poly(train$Quality.of.Sleep, 2), data = train)
model_summary <- summary(poly_model)
print(model_summary)

coefficients <- coef(poly_model)
coef_quadratic <- coefficients["poly(train$Quality.of.Sleep, 2)1"]
coef_linear <- coefficients["poly(train$Quality.of.Sleep, 2)2"]
intercept <- coefficients["(Intercept)"]

cat("Polynomial Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(coef_linear, 2), "x + ", round(coef_quadratic, 2), "x^2\n")

RSS <- sum(poly_model$residuals^2)
TSS <- sum((train$Daily.Steps - mean(train$Daily.Steps))^2)
p <- length(coef(poly_model))
n <- nrow(train)
F_statistic <- ((TSS - RSS) / (p - 1)) / (RSS / (n - p))
df1 <- p - 1
df2 <- n - p
alpha <- 0.05
p_value <- 1 - pf(F_statistic, df1, df2)

if (p_value < alpha) {
  cat("Reject the null hypothesis. The polynomial regression model is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The polynomial regression model is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Daily.Steps, main = "Polynomial Regression", xlab = "Quality.of.Sleep", ylab = "Daily.Steps")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(poly_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```

#### Test against Validation Set
```{r}
poly_model <- lm(valid$Daily.Steps ~ poly(valid$Quality.of.Sleep, 2), data = valid)
predictors <- attr(poly_model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted <- predict(poly_model, newdata = valid)
mse <- mean((valid$Daily.Steps - predicted)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Daily.Steps - predicted)^2) / sum((valid$Daily.Steps - mean(valid$Daily.Steps))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_poly <- sum(poly_model$residuals^2)
n_poly <- length(poly_model$residuals)
p_poly <- number_of_predictors
Cp_poly <- (SSE_poly / mse) - (n_poly - 2 * p_poly)
AIC_poly <- n_poly * log(SSE_poly / n_poly) + 2 * (p_poly + 1)
BIC_poly <- n_poly * log(SSE_poly / n_poly) + (p_poly + 1) * log(n_poly)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Polynomial Model:", p_poly, "\n")
cat("Mallow's Cp for the Polynomial Model:", Cp_poly, "\n")
cat("AIC for the Polynomial Model:", AIC_poly, "\n")
cat("BIC for the Polynomial Model:", BIC_poly, "\n")

plot(valid$Quality.of.Sleep, valid$Daily.Steps, main = "Polynomial Regression (Validation Set)", xlab = "Quality.of.Sleep", ylab = "Daily.Steps")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
poly_model_test <- lm(test$Daily.Steps ~ poly(test$Quality.of.Sleep, 2), data = test)
predictors <- attr(poly_model_test$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_test <- predict(poly_model_test, newdata = test)
mse_test <- mean((test$Daily.Steps - predicted_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- number_of_predictors
r_squared_test <- 1 - (sum((test$Daily.Steps - predicted_test)^2) / sum((test$Daily.Steps - mean(test$Daily.Steps))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)
SSE_poly_test <- sum(poly_model_test$residuals^2)
n_poly_test <- length(poly_model_test$residuals)
Cp_poly_test <- (SSE_poly_test / mse_test) - (n_poly_test - 2 * k_test)
AIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + 2 * (k_test + 1)
BIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + (k_test + 1) * log(n_poly_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Polynomial Model on the test set:", k_test, "\n")
cat("Mallow's Cp for the Polynomial Model on the test set:", Cp_poly_test, "\n")
cat("AIC for the Polynomial Model on the test set:", AIC_poly_test, "\n")
cat("BIC for the Polynomial Model on the test set:", BIC_poly_test, "\n")

plot(test$Quality.of.Sleep, test$Daily.Steps, main = "Polynomial Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Daily.Steps")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_test, col = "red", pch = 20)
```

Due to the structure of the data, the line of the polynomial regression model is like a **zig-zag shape**, instead of a smooth curve. This indicates that perhaps this is **not the perfect** regression model for this data. However, by looking at the evaluation metrics, it appears that the model has a **moderate level** of explanatory power and prediction accuracy, as indicated by the **low adjusted R-squared, and high MSE, RMSE values**. The model is statistically significant, but its performance on the validation and test sets suggests that it **may not be the best fit** for the data.


### Quality.of.Sleep v.s. Physical.Activity.Level
```{r}
poly_model <- lm(train$Physical.Activity.Level ~ poly(train$Quality.of.Sleep, 2), data = train)
model_summary <- summary(poly_model)
print(model_summary)

coefficients <- coef(poly_model)
coef_quadratic <- coefficients["poly(train$Quality.of.Sleep, 2)1"]
coef_linear <- coefficients["poly(train$Quality.of.Sleep, 2)2"]
intercept <- coefficients["(Intercept)"]

cat("Polynomial Linear Regression Model Equation: y = ", round(intercept, 2), " + ", round(coef_linear, 2), "x + ", round(coef_quadratic, 2), "x^2\n")

RSS <- sum(poly_model$residuals^2)
TSS <- sum((train$Physical.Activity.Level - mean(train$Physical.Activity.Level))^2)
p <- length(coef(poly_model))
n <- nrow(train)
F_statistic <- ((TSS - RSS) / (p - 1)) / (RSS / (n - p))
df1 <- p - 1
df2 <- n - p
alpha <- 0.05
p_value <- 1 - pf(F_statistic, df1, df2)

if (p_value < alpha) {
  cat("Reject the null hypothesis. The polynomial regression model is statistically significant.\n")
} else {
  cat("Fail to reject the null hypothesis. The polynomial regression model is not statistically significant.\n")
}

plot(train$Quality.of.Sleep, train$Physical.Activity.Level, main = "Polynomial Regression", xlab = "Quality.of.Sleep", ylab = "Physical.Activity.Level")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(poly_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```

#### Test against Validation Set
```{r}
poly_model <- lm(valid$Physical.Activity.Level ~ poly(valid$Quality.of.Sleep, 2), data = valid)
predictors <- attr(poly_model$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted <- predict(poly_model, newdata = valid)
mse <- mean((valid$Physical.Activity.Level - predicted)^2)
rmse <- sqrt(mse)
n <- nrow(valid)
k <- number_of_predictors
r_squared <- 1 - (sum((valid$Physical.Activity.Level - predicted)^2) / sum((valid$Physical.Activity.Level - mean(valid$Physical.Activity.Level))^2))
adjusted_r_squared <- 1 - (1 - r_squared) * (n - 1) / (n - k - 1)

SSE_poly <- sum(poly_model$residuals^2)
n_poly <- length(poly_model$residuals)
p_poly <- number_of_predictors
Cp_poly <- (SSE_poly / mse) - (n_poly - 2 * p_poly)
AIC_poly <- n_poly * log(SSE_poly / n_poly) + 2 * (p_poly + 1)
BIC_poly <- n_poly * log(SSE_poly / n_poly) + (p_poly + 1) * log(n_poly)

cat("Mean Squared Error (MSE):", mse, "\n")
cat("Root Mean Squared Error (RMSE):", rmse, "\n")
cat("Adjusted R-squared (Adjusted R^2):", adjusted_r_squared, "\n")
cat("Number of Predictors in the Polynomial Model:", p_poly, "\n")
cat("Mallow's Cp for the Polynomial Model:", Cp_poly, "\n")
cat("AIC for the Polynomial Model:", AIC_poly, "\n")
cat("BIC for the Polynomial Model:", BIC_poly, "\n")

plot(valid$Quality.of.Sleep, valid$Physical.Activity.Level, main = "Polynomial Regression (Validation Set)", xlab = "Quality.of.Sleep", ylab = "Physical.Activity.Level")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
poly_model_test <- lm(test$Physical.Activity.Level ~ poly(test$Quality.of.Sleep, 2), data = test)
predictors <- attr(poly_model_test$terms, "term.labels")
number_of_predictors <- length(predictors)

predicted_test <- predict(poly_model_test, newdata = test)
mse_test <- mean((test$Physical.Activity.Level - predicted_test)^2)
rmse_test <- sqrt(mse_test)
n_test <- nrow(test)
k_test <- number_of_predictors
r_squared_test <- 1 - (sum((test$Physical.Activity.Level - predicted_test)^2) / sum((test$Physical.Activity.Level - mean(test$Physical.Activity.Level))^2))
adjusted_r_squared_test <- 1 - (1 - r_squared_test) * (n_test - 1) / (n_test - k_test - 1)
SSE_poly_test <- sum(poly_model_test$residuals^2)
n_poly_test <- length(poly_model_test$residuals)
Cp_poly_test <- (SSE_poly_test / mse_test) - (n_poly_test - 2 * k_test)
AIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + 2 * (k_test + 1)
BIC_poly_test <- n_poly_test * log(SSE_poly_test / n_poly_test) + (k_test + 1) * log(n_poly_test)

cat("Mean Squared Error (MSE) on the test set:", mse_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_test, "\n")
cat("Adjusted R-squared (Adjusted R^2) on the test set:", adjusted_r_squared_test, "\n")
cat("Number of Predictors in the Polynomial Model on the test set:", k_test, "\n")
cat("Mallow's Cp for the Polynomial Model on the test set:", Cp_poly_test, "\n")
cat("AIC for the Polynomial Model on the test set:", AIC_poly_test, "\n")
cat("BIC for the Polynomial Model on the test set:", BIC_poly_test, "\n")

plot(test$Quality.of.Sleep, test$Physical.Activity.Level, main = "Polynomial Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Physical.Activity.Level")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_test, col = "red", pch = 20)
```

Due to the structure of the data, the line of the polynomial regression model is like a **zig-zag shape**, instead of a smooth curve. This indicates that perhaps this is **not the perfect** regression model for this data. None the less, the evaluation metrics tell us that this model has **limited explanatory power** and **prediction accuracy**. The **low adjusted R-squared values** for the validation and test sets, as well as relatively **high MSE and RMSE values**, suggest that the model **may not be the best fit** for the data.


# 2. Nonparametric Regression Models

## a. Kernal Regression
### Quality.of.Sleep v.s. Age
```{r}
library(locfit)
kernel_model <- locfit(Age ~ Quality.of.Sleep, data = train)
predicted_kernel_train <- predict(kernel_model, newdata = train)

kernel_model_summary <- summary(kernel_model)
print(kernel_model_summary)

mse_kernel_train <- mean((train$Age - predicted_kernel_train)^2)
rmse_kernel_train <- sqrt(mse_kernel_train)
n_train <- nrow(train)
k_kernel_train <- 1  
r_squared_kernel_train <- 1 - (sum((train$Age - predicted_kernel_train)^2) / sum((train$Age - mean(train$Age))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_kernel_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_kernel_train, "\n")
cat("R-squared on the training set:", r_squared_kernel_train, "\n")

plot(train$Quality.of.Sleep, train$Age, main = "Kernel Regression (Train Set)", xlab = "Quality of Sleep", ylab = "Age")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(kernel_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```

#### Test against Validation Set
```{r}
predicted_kernel <- predict(kernel_model, newdata = valid)

mse_kernel <- mean((valid$Age - predicted_kernel)^2)
rmse_kernel <- sqrt(mse_kernel)

n_kernel <- nrow(valid)
k_kernel <- 1 
r_squared_kernel <- 1 - (sum((valid$Age - predicted_kernel)^2) / sum((valid$Age - mean(valid$Age))^2))

cat("Mean Squared Error (MSE):", mse_kernel, "\n")
cat("Root Mean Squared Error (RMSE):", rmse_kernel, "\n")
cat("R-squared (R^2):", r_squared_kernel, "\n")

plot(valid$Quality.of.Sleep, valid$Age, main = "Kernel Regression (Validation Set)", xlab = "Quality of Sleep", ylab = "Age")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted_kernel, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
predicted_kernel_test <- predict(kernel_model, newdata = test)

mse_kernel_test <- mean((test$Age - predicted_kernel_test)^2)
rmse_kernel_test <- sqrt(mse_kernel_test)
n_kernel_test <- nrow(test)
r_squared_kernel_test <- 1 - (sum((test$Age - predicted_kernel_test)^2) / sum((test$Age - mean(test$Age))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_kernel_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_kernel_test, "\n")
cat("R-squared (R^2) on the test set:", r_squared_kernel_test, "\n")

plot(test$Quality.of.Sleep, test$Age, main = "Kernel Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Age")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_kernel_test, col = "red", pch = 20)
```


The kernel regression model for quality of sleep and age appears to provide a **reasonably good fit** to the data, as evidenced by the **relatively low MSE and RMSE values** and the **moderate R-squared values** for all three sets of data. The **test set** performs well compared to the validation and training sets, as it has lower MSE & RMSE values. This suggests that the **model's predictions on the test set are accurate**. The **R-squared value** on the test set suggests that the model explains **more than half** of the variance in the response variable for new, unseen data, which is a reasonably good fit.


### Quality.of.Sleep v.s. Sleep.Duration
```{r}
kernel_model <- locfit(Sleep.Duration ~ Quality.of.Sleep, data = train)
predicted_kernel_train <- predict(kernel_model, newdata = train)

kernel_model_summary <- summary(kernel_model)
print(kernel_model_summary)

mse_kernel_train <- mean((train$Sleep.Duration - predicted_kernel_train)^2)
rmse_kernel_train <- sqrt(mse_kernel_train)
n_train <- nrow(train)
k_kernel_train <- 1  
r_squared_kernel_train <- 1 - (sum((train$Sleep.Duration - predicted_kernel_train)^2) / sum((train$Sleep.Duration - mean(train$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_kernel_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_kernel_train, "\n")
cat("R-squared on the training set:", r_squared_kernel_train, "\n")

plot(train$Quality.of.Sleep, train$Sleep.Duration, main = "Kernel Regression (Train Set)", xlab = "Quality of Sleep", ylab = "Sleep.Duration")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(kernel_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```

#### Test against Validation Set
```{r}
predicted_kernel <- predict(kernel_model, newdata = valid)

mse_kernel <- mean((valid$Sleep.Duration - predicted_kernel)^2)
rmse_kernel <- sqrt(mse_kernel)

n_kernel <- nrow(valid)
k_kernel <- 1 
r_squared_kernel <- 1 - (sum((valid$Sleep.Duration - predicted_kernel)^2) / sum((valid$Sleep.Duration - mean(valid$Sleep.Duration))^2))

cat("Mean Squared Error (MSE):", mse_kernel, "\n")
cat("Root Mean Squared Error (RMSE):", rmse_kernel, "\n")
cat("R-squared (R^2):", r_squared_kernel, "\n")

plot(valid$Quality.of.Sleep, valid$Sleep.Duration, main = "Kernel Regression (Validation Set)", xlab = "Quality of Sleep", ylab = "Sleep.Duration")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted_kernel, col = "red", pch = 20)
```

# Test against Test Set
```{r}
predicted_kernel_test <- predict(kernel_model, newdata = test)

mse_kernel_test <- mean((test$Sleep.Duration - predicted_kernel_test)^2)
rmse_kernel_test <- sqrt(mse_kernel_test)
n_kernel_test <- nrow(test)
r_squared_kernel_test <- 1 - (sum((test$Sleep.Duration - predicted_kernel_test)^2) / sum((test$Sleep.Duration - mean(test$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_kernel_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_kernel_test, "\n")
cat("R-squared (R^2) on the test set:", r_squared_kernel_test, "\n")

plot(test$Quality.of.Sleep, test$Sleep.Duration, main = "Kernel Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Sleep.Duration")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_kernel_test, col = "red", pch = 20)
```


From the above evaluations, we can see that this kernel regression model appears to provide an **perfect fit** for the data. It shows **great predictive performance** with **very low MSE and RMSE values**. Additionally, the **high R-squared values** suggest that the model captures a **significant portion** of the relationship between the the quality of sleep and the sleep duration. The **R-squared value** on the test set suggests that the model explains **more than 3 quarters** of the variance in the sleep duration for new, unseen data.This indicates that this model is **highly reliable** for predicting the sleep duration based on the given data, and there is a **strong correlation** between the variables.


### Quality.of.Sleep v.s. Daily.Steps
```{r}
kernel_model <- locfit(Daily.Steps ~ Quality.of.Sleep, data = train)
predicted_kernel_train <- predict(kernel_model, newdata = train)

kernel_model_summary <- summary(kernel_model)
print(kernel_model_summary)

mse_kernel_train <- mean((train$Daily.Steps - predicted_kernel_train)^2)
rmse_kernel_train <- sqrt(mse_kernel_train)
n_train <- nrow(train)
k_kernel_train <- 1  
r_squared_kernel_train <- 1 - (sum((train$Daily.Steps - predicted_kernel_train)^2) / sum((train$Daily.Steps - mean(train$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_kernel_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_kernel_train, "\n")
cat("R-squared on the training set:", r_squared_kernel_train, "\n")

plot(train$Quality.of.Sleep, train$Daily.Steps, main = "Kernel Regression (Train Set)", xlab = "Quality of Sleep", ylab = "Daily.Steps")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(kernel_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```

#### Test against Validation Set
```{r}
predicted_kernel <- predict(kernel_model, newdata = valid)

mse_kernel <- mean((valid$Daily.Steps - predicted_kernel)^2)
rmse_kernel <- sqrt(mse_kernel)

n_kernel <- nrow(valid)
k_kernel <- 1 
r_squared_kernel <- 1 - (sum((valid$Daily.Steps - predicted_kernel)^2) / sum((valid$Daily.Steps - mean(valid$Daily.Steps))^2))

cat("Mean Squared Error (MSE):", mse_kernel, "\n")
cat("Root Mean Squared Error (RMSE):", rmse_kernel, "\n")
cat("R-squared (R^2):", r_squared_kernel, "\n")

plot(valid$Quality.of.Sleep, valid$Daily.Steps, main = "Kernel Regression (Validation Set)", xlab = "Quality of Sleep", ylab = "Daily.Steps")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted_kernel, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
predicted_kernel_test <- predict(kernel_model, newdata = test)

mse_kernel_test <- mean((test$Daily.Steps - predicted_kernel_test)^2)
rmse_kernel_test <- sqrt(mse_kernel_test)
n_kernel_test <- nrow(test)
r_squared_kernel_test <- 1 - (sum((test$Daily.Steps - predicted_kernel_test)^2) / sum((test$Daily.Steps - mean(test$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_kernel_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_kernel_test, "\n")
cat("R-squared (R^2) on the test set:", r_squared_kernel_test, "\n")

plot(test$Quality.of.Sleep, test$Daily.Steps, main = "Kernel Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Daily.Steps")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_kernel_test, col = "red", pch = 20)
```


For the quality of sleep and the daily steps, this kernel regression model **does not appear to provide a good fit** for the data. The **high MSE and RMSE values** suggest that the model's predictions have **large errors**. Additionally, the **low R-squared values** indicate that the model captures only a **small portion** of the relationship between the sleep quality and the number of daily steps. The **R-squared value** on the test set suggests that the model explains only approximately **15%** of the variance in the daily steps for new, unseen data. This is a **weak fit** and indicates that the model's **predictive power is limited**, **limited correlation**.


### Quality.of.Sleep v.s. Physical.Activity.Level
```{r}
kernel_model <- locfit(Physical.Activity.Level ~ Quality.of.Sleep, data = train)
predicted_kernel_train <- predict(kernel_model, newdata = train)

kernel_model_summary <- summary(kernel_model)
print(kernel_model_summary)

mse_kernel_train <- mean((train$Physical.Activity.Level - predicted_kernel_train)^2)
rmse_kernel_train <- sqrt(mse_kernel_train)
n_train <- nrow(train)
k_kernel_train <- 1  
r_squared_kernel_train <- 1 - (sum((train$Physical.Activity.Level - predicted_kernel_train)^2) / sum((train$Physical.Activity.Level - mean(train$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_kernel_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_kernel_train, "\n")
cat("R-squared on the training set:", r_squared_kernel_train, "\n")

plot(train$Quality.of.Sleep, train$Physical.Activity.Level, main = "Kernel Regression (Train Set)", xlab = "Quality of Sleep", ylab = "Daily.Steps")
xseq <- seq(min(train$Quality.of.Sleep), max(train$Quality.of.Sleep), length.out = length(train$Quality.of.Sleep))
yhat <- predict(kernel_model, newdata = data.frame(Quality.of.Sleep = xseq))
lines(xseq, yhat, col = "red")
```

#### Test against Validation Set
```{r}
predicted_kernel <- predict(kernel_model, newdata = valid)

mse_kernel <- mean((valid$Physical.Activity.Level - predicted_kernel)^2)
rmse_kernel <- sqrt(mse_kernel)

n_kernel <- nrow(valid)
k_kernel <- 1 
r_squared_kernel <- 1 - (sum((valid$Physical.Activity.Level - predicted_kernel)^2) / sum((valid$Physical.Activity.Level - mean(valid$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE):", mse_kernel, "\n")
cat("Root Mean Squared Error (RMSE):", rmse_kernel, "\n")
cat("R-squared (R^2):", r_squared_kernel, "\n")

plot(valid$Quality.of.Sleep, valid$Physical.Activity.Level, main = "Kernel Regression (Validation Set)", xlab = "Quality of Sleep", ylab = "Physical.Activity.Level")
lines(xseq, yhat, col = "blue")
points(valid$Quality.of.Sleep, predicted_kernel, col = "red", pch = 20)
```

#### Test against Test Set
```{r}
predicted_kernel_test <- predict(kernel_model, newdata = test)

mse_kernel_test <- mean((test$Physical.Activity.Level - predicted_kernel_test)^2)
rmse_kernel_test <- sqrt(mse_kernel_test)
n_kernel_test <- nrow(test)
r_squared_kernel_test <- 1 - (sum((test$Physical.Activity.Level - predicted_kernel_test)^2) / sum((test$Physical.Activity.Level - mean(test$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_kernel_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_kernel_test, "\n")
cat("R-squared (R^2) on the test set:", r_squared_kernel_test, "\n")

plot(test$Quality.of.Sleep, test$Physical.Activity.Level, main = "Kernel Regression (Test Set)", xlab = "Quality of Sleep", ylab = "Physical.Activity.Level")
lines(xseq, yhat, col = "blue")
points(test$Quality.of.Sleep, predicted_kernel_test, col = "red", pch = 20)
```


Based on the above evaluation metrics, this kernel regression model **does not appear to provide a strong fit for the data**. The **relatively high MSE and RMSE values** suggest that the model's predictions have substantial **errors.** Moreover, the **low R-squared values** indicate that the model captures only a **small portion** of the relationship between the sleep quality and the level of physical activity. This suggests a **weak or limited correlation** between the variables.


## b. Regression Trees
### Quality.of.Sleep v.s. Age
```{r}
library(rpart)

tree_model <- rpart(Age ~ Quality.of.Sleep, data = train)
print(tree_model)

plot(tree_model)
text(tree_model, use.n=TRUE, cex = 0.7)
predicted_tree_train <- predict(tree_model, newdata = train)

mse_tree_train <- mean((train$Age - predicted_tree_train)^2)
rmse_tree_train <- sqrt(mse_tree_train)
n_train <- nrow(train)
k_tree_train <- 1
r_squared_tree_train <- 1 - (sum((train$Age - predicted_tree_train)^2) / sum((train$Age - mean(train$Age))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_tree_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_tree_train, "\n")
cat("R-squared on the training set:", r_squared_tree_train, "\n")

predicted_tree_valid <- predict(tree_model, newdata = valid)

mse_tree_valid <- mean((valid$Age - predicted_tree_valid)^2)
rmse_tree_valid <- sqrt(mse_tree_valid)
n_valid <- nrow(valid)
k_tree_valid <- 1 
r_squared_tree_valid <- 1 - (sum((valid$Age - predicted_tree_valid)^2) / sum((valid$Age - mean(valid$Age))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_tree_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_tree_valid, "\n")
cat("R-squared on the validation set:", r_squared_tree_valid, "\n")

predicted_tree_test <- predict(tree_model, newdata = test)

mse_tree_test <- mean((test$Age - predicted_tree_test)^2)
rmse_tree_test <- sqrt(mse_tree_test)
n_test <- nrow(test)
r_squared_tree_test <- 1 - (sum((test$Age - predicted_tree_test)^2) / sum((test$Age - mean(test$Age))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_tree_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_tree_test, "\n")
cat("R-squared on the test set:", r_squared_tree_test, "\n")
```


The regression tree model for quality of sleep and age appears to provide a **good fit** for the data. The **relatively low MSE and RMSE values** suggest that the model's predictions have **relatively small errors**. Additionally, the **moderate R-squared values** indicate that the model captures a **significant portion** of the relationship between the variables. Yet, the r-squared value on the test set show that it may not predict accurately. Thus, it is suggested that there is a **moderately correlation** between the the quality of sleep and the age.


### Quality.of.Sleep v.s. Sleep.Duration
```{r}
tree_model <- rpart(Sleep.Duration ~ Quality.of.Sleep, data = train)
print(tree_model)

plot(tree_model)
text(tree_model, use.n=TRUE, cex = 0.7)
predicted_tree_train <- predict(tree_model, newdata = train)

mse_tree_train <- mean((train$Sleep.Duration - predicted_tree_train)^2)
rmse_tree_train <- sqrt(mse_tree_train)
n_train <- nrow(train)
k_tree_train <- 1
r_squared_tree_train <- 1 - (sum((train$Sleep.Duration - predicted_tree_train)^2) / sum((train$Sleep.Duration - mean(train$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_tree_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_tree_train, "\n")
cat("R-squared on the training set:", r_squared_tree_train, "\n")

predicted_tree_valid <- predict(tree_model, newdata = valid)

mse_tree_valid <- mean((valid$Sleep.Duration - predicted_tree_valid)^2)
rmse_tree_valid <- sqrt(mse_tree_valid)
n_valid <- nrow(valid)
k_tree_valid <- 1 
r_squared_tree_valid <- 1 - (sum((valid$Sleep.Duration - predicted_tree_valid)^2) / sum((valid$Sleep.Duration - mean(valid$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_tree_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_tree_valid, "\n")
cat("R-squared on the validation set:", r_squared_tree_valid, "\n")

predicted_tree_test <- predict(tree_model, newdata = test)

mse_tree_test <- mean((test$Sleep.Duration - predicted_tree_test)^2)
rmse_tree_test <- sqrt(mse_tree_test)
n_test <- nrow(test)
r_squared_tree_test <- 1 - (sum((test$Sleep.Duration - predicted_tree_test)^2) / sum((test$Sleep.Duration - mean(test$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_tree_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_tree_test, "\n")
cat("R-squared on the test set:", r_squared_tree_test, "\n")
```


This regression tree model has **very low MSE and RMSE** values suggest that the model's predictions have **extremely small errors**. The **high R-squared values** indicate that the model captures a **significant portion** of the relationship between the sleep quality and the sleep duration. This suggests a **fairly strong correlation** between the variables.


### Quality.of.Sleep v.s. Daily.Steps
```{r}
tree_model <- rpart(Daily.Steps ~ Quality.of.Sleep, data = train)
print(tree_model)

plot(tree_model)
text(tree_model, use.n=TRUE, cex = 0.7)
predicted_tree_train <- predict(tree_model, newdata = train)

mse_tree_train <- mean((train$Daily.Steps - predicted_tree_train)^2)
rmse_tree_train <- sqrt(mse_tree_train)
n_train <- nrow(train)
k_tree_train <- 1
r_squared_tree_train <- 1 - (sum((train$Daily.Steps - predicted_tree_train)^2) / sum((train$Daily.Steps - mean(train$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_tree_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_tree_train, "\n")
cat("R-squared on the training set:", r_squared_tree_train, "\n")

predicted_tree_valid <- predict(tree_model, newdata = valid)

mse_tree_valid <- mean((valid$Daily.Steps - predicted_tree_valid)^2)
rmse_tree_valid <- sqrt(mse_tree_valid)
n_valid <- nrow(valid)
k_tree_valid <- 1 
r_squared_tree_valid <- 1 - (sum((valid$Daily.Steps - predicted_tree_valid)^2) / sum((valid$Daily.Steps - mean(valid$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_tree_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_tree_valid, "\n")
cat("R-squared on the validation set:", r_squared_tree_valid, "\n")

predicted_tree_test <- predict(tree_model, newdata = test)

mse_tree_test <- mean((test$Daily.Steps - predicted_tree_test)^2)
rmse_tree_test <- sqrt(mse_tree_test)
n_test <- nrow(test)
r_squared_tree_test <- 1 - (sum((test$Daily.Steps - predicted_tree_test)^2) / sum((test$Daily.Steps - mean(test$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_tree_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_tree_test, "\n")
cat("R-squared on the test set:", r_squared_tree_test, "\n")
```


Based on the above, it can be inferred that this regression tree model **does not provide a strong fit** for the data. The **relatively high MSE and RMSE values** indicate that the model's predictions have a **large spread of errors**. The **low R-squared values** suggest that the model explains only a **small proportion** of the variance in the daily steps variable, indicating a **weak correlation** between the quality of sleep and the number of daily steps.


### Quality.of.Sleep v.s. Physical.Activity.Level
```{r}
tree_model <- rpart(Physical.Activity.Level ~ Quality.of.Sleep, data = train)
print(tree_model)

plot(tree_model)
text(tree_model, use.n=TRUE, cex = 0.7)
predicted_tree_train <- predict(tree_model, newdata = train)

mse_tree_train <- mean((train$Physical.Activity.Level - predicted_tree_train)^2)
rmse_tree_train <- sqrt(mse_tree_train)
n_train <- nrow(train)
k_tree_train <- 1
r_squared_tree_train <- 1 - (sum((train$Physical.Activity.Level - predicted_tree_train)^2) / sum((train$Physical.Activity.Level - mean(train$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_tree_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_tree_train, "\n")
cat("R-squared on the training set:", r_squared_tree_train, "\n")

predicted_tree_valid <- predict(tree_model, newdata = valid)

mse_tree_valid <- mean((valid$Physical.Activity.Level - predicted_tree_valid)^2)
rmse_tree_valid <- sqrt(mse_tree_valid)
n_valid <- nrow(valid)
k_tree_valid <- 1 
r_squared_tree_valid <- 1 - (sum((valid$Physical.Activity.Level - predicted_tree_valid)^2) / sum((valid$Physical.Activity.Level - mean(valid$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_tree_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_tree_valid, "\n")
cat("R-squared on the validation set:", r_squared_tree_valid, "\n")

predicted_tree_test <- predict(tree_model, newdata = test)

mse_tree_test <- mean((test$Physical.Activity.Level - predicted_tree_test)^2)
rmse_tree_test <- sqrt(mse_tree_test)
n_test <- nrow(test)
r_squared_tree_test <- 1 - (sum((test$Physical.Activity.Level - predicted_tree_test)^2) / sum((test$Physical.Activity.Level - mean(test$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_tree_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_tree_test, "\n")
cat("R-squared on the test set:", r_squared_tree_test, "\n")
```

The regression tree model **does not provide a strong fit** for the data. The **relatively high MSE and RMSE values** indicate that the model's predictions have a **large spread of errors**. The **low R-squared values** suggest that the model explains only a **small proportion** of the variance in the physical activity level variable, indicating a **weak correlation**.


## c. Locally Weighted Regression
### Quality.of.Sleep v.s. Age
```{r}
library(ggplot2)

loess_model <- loess(Age ~ Quality.of.Sleep, data = train, span = 0.8) 
predicted_loess_train <- predict(loess_model, newdata = train)

mse_loess_train <- mean((train$Age - predicted_loess_train)^2)
rmse_loess_train <- sqrt(mse_loess_train)
r_squared_loess_train <- 1 - (sum((train$Age - predicted_loess_train)^2) / sum((train$Age - mean(train$Age))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_loess_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_loess_train, "\n")
cat("R-squared on the training set:", r_squared_loess_train, "\n")

ggplot(train, aes(x = Quality.of.Sleep, y = Age)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "red") +
  labs(title = "LOESS Regression (Train Set)", x = "Quality of Sleep", y = "Age")
```

#### Test against Validation Set
```{r}
predicted_loess_valid <- predict(loess_model, newdata = valid)

mse_loess_valid <- mean((valid$Age - predicted_loess_valid)^2)
rmse_loess_valid <- sqrt(mse_loess_valid)
r_squared_loess_valid <- 1 - (sum((valid$Age - predicted_loess_valid)^2) / sum((valid$Age - mean(valid$Age))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_loess_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_loess_valid, "\n")
cat("R-squared on the validation set:", r_squared_loess_valid, "\n")

predicted_data <- data.frame(Quality.of.Sleep = valid$Quality.of.Sleep, Age = predicted_loess_valid)

ggplot(valid, aes(x = Quality.of.Sleep, y = Age)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data, aes(x = Quality.of.Sleep, y = Age), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Validation Set)", x = "Quality of Sleep", y = "Age")
```

#### Test against Test Set
```{r}
predicted_loess_test <- predict(loess_model, newdata = test)
mse_loess_test <- mean((test$Age - predicted_loess_test)^2)
rmse_loess_test <- sqrt(mse_loess_test)
r_squared_loess_test <- 1 - (sum((test$Age - predicted_loess_test)^2) / sum((test$Age - mean(test$Age))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_loess_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_loess_test, "\n")
cat("R-squared on the test set:", r_squared_loess_test, "\n")

predicted_data_test <- data.frame(Quality.of.Sleep = test$Quality.of.Sleep, Age = predicted_loess_test)

ggplot(test, aes(x = Quality.of.Sleep, y = Age)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data_test, aes(x = Quality.of.Sleep, y = Age), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Test Set)", x = "Quality of Sleep", y = "Age")
```


This locally weighted regression model for the quality of sleep and the age has **accurate** predictions. It has **lower MSE and RMSE values**, suggesting that the model has small errors. Furthermore, the **moderately high R-squared values** indicate a **strong correlation** and a **good fit** between the variables.


### Quality.of.Sleep v.s. Sleep.Duration
```{r}
loess_model <- loess(Sleep.Duration ~ Quality.of.Sleep, data = train, span = 0.8) 
predicted_loess_train <- predict(loess_model, newdata = train)

mse_loess_train <- mean((train$Sleep.Duration - predicted_loess_train)^2)
rmse_loess_train <- sqrt(mse_loess_train)
r_squared_loess_train <- 1 - (sum((train$Sleep.Duration - predicted_loess_train)^2) / sum((train$Sleep.Duration - mean(train$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_loess_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_loess_train, "\n")
cat("R-squared on the training set:", r_squared_loess_train, "\n")

ggplot(train, aes(x = Quality.of.Sleep, y = Sleep.Duration)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "red") +
  labs(title = "LOESS Regression (Train Set)", x = "Quality of Sleep", y = "Sleep.Duration")
```

#### Test against Validation Set
```{r}
predicted_loess_valid <- predict(loess_model, newdata = valid)

mse_loess_valid <- mean((valid$Sleep.Duration - predicted_loess_valid)^2)
rmse_loess_valid <- sqrt(mse_loess_valid)
r_squared_loess_valid <- 1 - (sum((valid$Sleep.Duration - predicted_loess_valid)^2) / sum((valid$Sleep.Duration - mean(valid$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_loess_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_loess_valid, "\n")
cat("R-squared on the validation set:", r_squared_loess_valid, "\n")

predicted_data <- data.frame(Quality.of.Sleep = valid$Quality.of.Sleep, Age = predicted_loess_valid)

ggplot(valid, aes(x = Quality.of.Sleep, y = Sleep.Duration)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data, aes(x = Quality.of.Sleep, y = Age), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Validation Set)", x = "Quality of Sleep", y = "Sleep.Duration")
```

#### Test against Test Set
```{r}
predicted_loess_test <- predict(loess_model, newdata = test)
mse_loess_test <- mean((test$Sleep.Duration - predicted_loess_test)^2)
rmse_loess_test <- sqrt(mse_loess_test)
r_squared_loess_test <- 1 - (sum((test$Sleep.Duration - predicted_loess_test)^2) / sum((test$Sleep.Duration - mean(test$Sleep.Duration))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_loess_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_loess_test, "\n")
cat("R-squared on the test set:", r_squared_loess_test, "\n")

predicted_data_test <- data.frame(Quality.of.Sleep = test$Quality.of.Sleep, Sleep.Duration = predicted_loess_test)

ggplot(test, aes(x = Quality.of.Sleep, y = Sleep.Duration)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data_test, aes(x = Quality.of.Sleep, y = Sleep.Duration), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Test Set)", x = "Quality of Sleep", y = "Sleep.Duration")
```


The locally weighted regression model **performs great** for the quality of sleep and the sleep duration. The **very low MSE and RMSE values** indicate highly accurate predictions with **minimal errors**. Moreover, the **very high R-squared values** demonstrate an **outstanding fit** between the the quality of sleep and the sleep duration. The results suggest a **strong and positive relationship** with **high correlation** and **predictive power**.


### Quality.of.Sleep v.s. Daily.Steps
```{r}
loess_model <- loess(Daily.Steps ~ Quality.of.Sleep, data = train, span = 0.8)  # Adjust the span as needed
predicted_loess_train <- predict(loess_model, newdata = train)

mse_loess_train <- mean((train$Daily.Steps - predicted_loess_train)^2)
rmse_loess_train <- sqrt(mse_loess_train)
r_squared_loess_train <- 1 - (sum((train$Daily.Steps - predicted_loess_train)^2) / sum((train$Daily.Steps - mean(train$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_loess_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_loess_train, "\n")
cat("R-squared on the training set:", r_squared_loess_train, "\n")

ggplot(train, aes(x = Quality.of.Sleep, y = Daily.Steps)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "red") +
  labs(title = "LOESS Regression (Train Set)", x = "Quality of Sleep", y = "Daily.Steps")
```

#### Test against Validation Set
```{r}
predicted_loess_valid <- predict(loess_model, newdata = valid)

mse_loess_valid <- mean((valid$Daily.Steps - predicted_loess_valid)^2)
rmse_loess_valid <- sqrt(mse_loess_valid)
r_squared_loess_valid <- 1 - (sum((valid$Daily.Steps - predicted_loess_valid)^2) / sum((valid$Daily.Steps - mean(valid$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_loess_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_loess_valid, "\n")
cat("R-squared on the validation set:", r_squared_loess_valid, "\n")

predicted_data <- data.frame(Quality.of.Sleep = valid$Quality.of.Sleep, Age = predicted_loess_valid)

ggplot(valid, aes(x = Quality.of.Sleep, y = Daily.Steps)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data, aes(x = Quality.of.Sleep, y = Age), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Validation Set)", x = "Quality of Sleep", y = "Daily.Steps")
```

#### Test against Test Set
```{r}
predicted_loess_test <- predict(loess_model, newdata = test)
mse_loess_test <- mean((test$Daily.Steps - predicted_loess_test)^2)
rmse_loess_test <- sqrt(mse_loess_test)
r_squared_loess_test <- 1 - (sum((test$Daily.Steps - predicted_loess_test)^2) / sum((test$Daily.Steps - mean(test$Daily.Steps))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_loess_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_loess_test, "\n")
cat("R-squared on the test set:", r_squared_loess_test, "\n")

predicted_data_test <- data.frame(Quality.of.Sleep = test$Quality.of.Sleep, Daily.Steps = predicted_loess_test)

ggplot(test, aes(x = Quality.of.Sleep, y = Daily.Steps)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data_test, aes(x = Quality.of.Sleep, y = Daily.Steps), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Test Set)", x = "Quality of Sleep", y = "Daily.Steps")
```


For this locally weighted regression model, as shown by the **high MSE and RMSE values**, it is suggested that the **accuracy is low** and the **predictions have large errors**. Moreover, the **low value of r-squared** means that the model explains only a **small proportion** of the variance in the daily steps variable. Thus, this model has a **weaker fit** and the correlation between the variables is **small.**


### Quality.of.Sleep v.s. Physical.Activity.Level
```{r}
loess_model <- loess(Physical.Activity.Level ~ Quality.of.Sleep, data = train, span = 0.8)
predicted_loess_train <- predict(loess_model, newdata = train)

mse_loess_train <- mean((train$Physical.Activity.Level - predicted_loess_train)^2)
rmse_loess_train <- sqrt(mse_loess_train)
r_squared_loess_train <- 1 - (sum((train$Physical.Activity.Level - predicted_loess_train)^2) / sum((train$Physical.Activity.Level - mean(train$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the training set:", mse_loess_train, "\n")
cat("Root Mean Squared Error (RMSE) on the training set:", rmse_loess_train, "\n")
cat("R-squared on the training set:", r_squared_loess_train, "\n")

ggplot(train, aes(x = Quality.of.Sleep, y = Physical.Activity.Level)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "red") +
  labs(title = "LOESS Regression (Train Set)", x = "Quality of Sleep", y = "Physical.Activity.Level")
```

#### Test against Validation Set
```{r}
predicted_loess_valid <- predict(loess_model, newdata = valid)

mse_loess_valid <- mean((valid$Physical.Activity.Level - predicted_loess_valid)^2)
rmse_loess_valid <- sqrt(mse_loess_valid)
r_squared_loess_valid <- 1 - (sum((valid$Physical.Activity.Level - predicted_loess_valid)^2) / sum((valid$Physical.Activity.Level - mean(valid$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the validation set:", mse_loess_valid, "\n")
cat("Root Mean Squared Error (RMSE) on the validation set:", rmse_loess_valid, "\n")
cat("R-squared on the validation set:", r_squared_loess_valid, "\n")

predicted_data <- data.frame(Quality.of.Sleep = valid$Quality.of.Sleep, Age = predicted_loess_valid)

ggplot(valid, aes(x = Quality.of.Sleep, y = Physical.Activity.Level)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data, aes(x = Quality.of.Sleep, y = Age), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Validation Set)", x = "Quality of Sleep", y = "Physical.Activity.Level")
```

#### Test against Test Set
```{r}
predicted_loess_test <- predict(loess_model, newdata = test)
mse_loess_test <- mean((test$Physical.Activity.Level - predicted_loess_test)^2)
rmse_loess_test <- sqrt(mse_loess_test)
r_squared_loess_test <- 1 - (sum((test$Physical.Activity.Level - predicted_loess_test)^2) / sum((test$Physical.Activity.Level - mean(test$Physical.Activity.Level))^2))

cat("Mean Squared Error (MSE) on the test set:", mse_loess_test, "\n")
cat("Root Mean Squared Error (RMSE) on the test set:", rmse_loess_test, "\n")
cat("R-squared on the test set:", r_squared_loess_test, "\n")

predicted_data_test <- data.frame(Quality.of.Sleep = test$Quality.of.Sleep, Physical.Activity.Level = predicted_loess_test)

ggplot(test, aes(x = Quality.of.Sleep, y = Physical.Activity.Level)) +
  geom_point() +
  geom_smooth(method = "loess", span = 0.8, col = "blue") +
  geom_point(data = predicted_data_test, aes(x = Quality.of.Sleep, y = Physical.Activity.Level), col = "red", pch = 20) +
  labs(title = "LOESS Regression (Test Set)", x = "Quality of Sleep", y = "Physical.Activity.Level")
```


From the above analysis, we can see that the MSE and RMSE values are quite high. This tells us that the locally weighted regression model provides **less accurate predictions** with **larger errors**. Furthermore, the **R-squared value for the test set is extremely low**, indicating that the model explains a **negligible proportion** of the variance in the physical activity level variable. Thus, this model has a **weak fit** to the data, and there is **little to no linear relationship or correlation**.

# Conclusion

By doing this assignment, I learned that the dataset I decided to analyze is more suitable for non-parametric regression models. The reason is because of the structure of the dataset. The values of quality of sleep are discrete, meaning that it is a value ranging from 4 to 9. Hence, for parametric regression models like polynomial model, the curve would be zig-zag, instead of a smooth curve. By looking at the evaluation metrics, the values from nonparametric models are mostly better than that from parametric models.

The variables I decided to compare with the quality of sleep are the age, the sleep duration, the daily steps, and the physical activity level. Interestingly, results show that sleep duration has the highest positive correlation with sleep quality. It has high r-squared values in many regression models, showing that the models can accurately predict new, unseen data.


# Possible Problems To Investigate For Future Studies

1. If I adjust the proportion of the training, validation, and test sets, would the results be different ?

2. Is there any other variables that can incluence the quality of sleep ?

3. Is there any other variables that can influence the factors of quality of sleep (ex. sleep duration) ?
